---
title: "Chapter 2: Getting Started"
---

# Chapter 2: Getting Started

<section>

## 2.2 Analyzing Algorithms

You can use a ***loop invariant*** to inductively prove that an algorithm is correct:

> **Initialization**: It is true prior to the first iteration of the loop.  
> **Maintenance**: If it is true before an iteration of the loop, it remains true before the next iteration.  
> **Termination**: When the loop terminates, the invariant gives us a useful property that helps show that the algorithm is correct.  
> <Citation title="clrs" text="page 18" />

*Introduction to Algorithms* uses a single-processor single-threaded ***random-access machine (RAM)*** model when analyzing algorithms:
* Arithmetic (add, subtract, multiply, divide, remainder, floor, ceiling)
* Data Movement (load, store, copy)
* Control (conditional and unconditional branch, subroutine call and return)
* Bit Operations (e.g. $2^k$ can be done with a bitwise shift when *k* is a small enough positive integer)

## 2.2 Exercises

---

### Problem 2.2-2
> Consider sorting $n$ numbers stored in array $A$ by first finding the smallest element of $A$ and exchanging it with the element in $A[1]$. Then find the second smallest element of $A$, and exchange it with $A[2]$. Continue in this manner for the first $n-1$ elements of $A$. Write pseudocode for this algorithm, which is known as **selection sort**. What loop invariant does this algorithm maintain? Why does it need to run for only the first $n-1$ elements, rather than for all $n$ elements? Give the best-case and worst-case running times of selection sort in $\Theta$-notation.
> <Citation title="clrs" text="page 27" />

<Solution title="2_2_2">

`embed:test_2_2_2.py`

#### Proof of Correctness

##### Part 1

***Loop invariant***: For an input of size $n$, at the end of the $(i+1)^{th}$ iteration of the for loop of lines 20-27, $\forall j,k: A[j] \leq A[k], 0 \leq j \leq i \leq k < n$

***Induction hypothesis*** $P(n)$: This loop invariant holds for all $0 \leq i < n$

***Case*** $P(1)$:

From our *induction hypothesis*, we have $0 \leq i < 1$, so $i=0$.

Substituting $i=0$ and $n=1$ into our loop invariant, we have: $\forall j,k: A[j] \leq A[k], 0 \leq j \leq 0 \leq k < 1$. This reduces to $A[0] \leq A[0]$ which is trivially true.

***Case*** $P(2)$:

From our *induction hypothesis*, we have $0 \leq i < 2$.

**During the $1^{st}$ iteration** ($i=0$), on lines 21-24, we find the smallest element in $A$ ($A[i ... n-1]$) and store that index in $small$.

On lines 25-27, we swap the elements at $A[small]$ and $A[0]$ ($A[small]$ and $A[i]$).

After this $1^{st}$ loop, the smallest element in $A$ is at $A[0]$.

Substituting $i=0$ and $n=2$ into our loop invariant, we have: $\forall j,k: A[j] \leq A[k], 0 \leq j \leq 0 \leq k < 2$

This simplifies to: $A[0] \leq A[1]$.

This is true since we know that the smallest element in $A$ is at $A[0]$, and the smallest element in $A$ is less than or equal to any other element in $A$.

**During the $2^{nd}$ iteration** ($i=1$), on lines 21-24, we find the smallest element in $A[1 ... 1]$ ($A[i ... n-1]$) and store that index in $small$. There is only one element in $A[1]$, so $small=1$.

On lines 25-27, we swap the elements at $A[1]$ and $A[1]$ ($A[small]$ and $A[i]$).

$A$ was not changed during this iteration of the loop since $A[0]$ was not touched and $A[1]$ was 'swapped' in place.

Substituting $i=1$ and $n=2$ into our loop invariant, we have: $\forall j,k: A[j] \leq A[k], 0 \leq j \leq 1 \leq k < 2$

This simplifies to: $\forall j: A[j] \leq A[1], 0 \leq j \leq 1$. We can evaluate this for all values of $j$:
* $A[0] \leq A[1]$ is true by the same logic as after the $1^{st}$ iteration in this case since $A$ has not changed since then.
* $A[1] \leq A[1]$ is trivially true.

***Case*** $P(n+1)$:

*Assume $P(n)$*: $\forall j,k: A[j] \leq A[k], 0 \leq j \leq i \leq k < n, 0 \leq i < n$

Substituting $n=n+1$ into our loop invariant, we have: $\forall j,k: A[j] \leq A[k], 0 \leq j \leq i \leq k < n+1, 0 \leq i < n+1$

Since we have $P(n)$ assumed, we just need to prove the difference: $\forall j,k: A[j] \leq A[k], 0 < j \leq i \leq k < n+1$

This simplifies to: $\forall k:$

##### Part 2

***Loop invariant***: For an input of size $n$, at the end of the $i^{th}$ iteration of the for loop of lines 20-27, $\forall j: A[j] \leq A[i], \forall j \leq i$

***Induction hypothesis***: This loop invariant holds for all $i \leq n$

***Case*** $n=1$:

Our loop invariant should hold for $i \leq 1$, i.e. $i=1$.

So $A[j] \leq A[1], \forall j \leq 1$, i.e. $j=1$.

$A[1] \leq A[1]$ is trivially true. 

***Case*** $n=i+1$:

Assume $A[j] \leq A[i], \forall j \leq i, i \leq n$.

</Solution>

---

### Problem 2.2-3
> Consider linear search again (see Exercise 2.1-3). How many elements of the input sequence need to be checked on average, assuming that the element being searched for is equally likely to be any element in the array? How about the worst case? What are the average-case and worst-case running times of linear search in $\Theta$-notation? Justify your answers.
> <Citation title="clrs" text="page 27" />

</section>
<section>

## 2.3 Designing Algorithms

Incremental (e.g. insertion sort)

Divide and Conquer (e.g. merge sort)
* usually recursive

Divide the problem into a number of subproblems

Conquer the subproblems by solving them recursively. If the subproblem sizes are small enough, however, just solve the subproblems in a straightforward manner.

Combine the solutions to the subproblems into the solution for the original problem.

Introduction to Algorithms Second Edition page 28


[Recursive algorithms] can often be described by a recurrence equation or recurrence

Introduction to Algorithms Second Edition page 32
</section>
